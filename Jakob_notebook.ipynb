{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQKOKFV_Z3zX"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requires Python 3.10 and Poetry 1.6. Run setup commands to begin:\n",
    "```\n",
    "!poetry install\n",
    "!poetry run jupyter lab\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQKOKFV_Z3zX"
   },
   "source": [
    "Load libraries and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m pd\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mmax_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/machine-learning-exam-dnZALQ3X-py3.10/lib/python3.10/site-packages/matplotlib/pyplot.py:66\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _docstring\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     65\u001b[0m     FigureCanvasBase, FigureManagerBase, MouseButton)\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfigure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Figure, FigureBase, figaspect\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgridspec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSpec, SubplotSpec\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rcsetup, rcParamsDefault, rcParamsOrig\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/machine-learning-exam-dnZALQ3X-py3.10/lib/python3.10/site-packages/matplotlib/figure.py:43\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _blocking_input, backend_bases, _docstring, projections\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     45\u001b[0m     Artist, allow_rasterization, _finalize_rasterization)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     DrawEvent, FigureCanvasBase, NonGuiException, MouseButton, _get_renderer)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/machine-learning-exam-dnZALQ3X-py3.10/lib/python3.10/site-packages/matplotlib/projections/__init__.py:55\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mNon-separable transforms that map from data space to screen space.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m`matplotlib.projections.polar` may also be of interest.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m axes, _docstring\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AitoffAxes, HammerAxes, LambertAxes, MollweideAxes\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolarAxes\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/machine-learning-exam-dnZALQ3X-py3.10/lib/python3.10/site-packages/matplotlib/axes/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _base\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_axes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Backcompat.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_axes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Axes \u001b[38;5;28;01mas\u001b[39;00m Subplot\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/machine-learning-exam-dnZALQ3X-py3.10/lib/python3.10/site-packages/matplotlib/axes/_axes.py:47\u001b[0m\n\u001b[1;32m     39\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# The axes module contains all the wrappers to plotting functions.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# All the other methods should go in the _AxesBase class.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;129m@_docstring\u001b[39m\u001b[38;5;241m.\u001b[39minterpd\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAxes\u001b[39;00m(_AxesBase):\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    An Axes object encapsulates all the elements of an individual (sub-)plot in\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    a figure.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m### Labelling, legend and texts\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/machine-learning-exam-dnZALQ3X-py3.10/lib/python3.10/site-packages/matplotlib/axes/_base.py:741\u001b[0m, in \u001b[0;36m_AxesBase.__init_subclass__\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m    732\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_deprecated(\n\u001b[1;32m    733\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3.6\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    734\u001b[0m         pending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease report \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    739\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis to the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m author.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_subclass_uses_cla \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcla\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m parent_uses_cla\n\u001b[0;32m--> 741\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__init_subclass__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/machine-learning-exam-dnZALQ3X-py3.10/lib/python3.10/site-packages/matplotlib/artist.py:150\u001b[0m, in \u001b[0;36mArtist.__init_subclass__\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_set_signature_and_docstring\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/machine-learning-exam-dnZALQ3X-py3.10/lib/python3.10/site-packages/matplotlib/artist.py:178\u001b[0m, in \u001b[0;36mArtist._update_set_signature_and_docstring\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m__signature__ \u001b[38;5;241m=\u001b[39m Signature(\n\u001b[1;32m    169\u001b[0m     [Parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, Parameter\u001b[38;5;241m.\u001b[39mPOSITIONAL_OR_KEYWORD),\n\u001b[1;32m    170\u001b[0m      \u001b[38;5;241m*\u001b[39m[Parameter(prop, Parameter\u001b[38;5;241m.\u001b[39mKEYWORD_ONLY, default\u001b[38;5;241m=\u001b[39m_UNSET)\n\u001b[1;32m    171\u001b[0m        \u001b[38;5;28;01mfor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m ArtistInspector(\u001b[38;5;28mcls\u001b[39m)\u001b[38;5;241m.\u001b[39mget_setters()\n\u001b[1;32m    172\u001b[0m        \u001b[38;5;28;01mif\u001b[39;00m prop \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m Artist\u001b[38;5;241m.\u001b[39m_PROPERTIES_EXCLUDED_FROM_SET]])\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m_autogenerated_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet multiple properties at once.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported properties are\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[43mkwdoc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/machine-learning-exam-dnZALQ3X-py3.10/lib/python3.10/site-packages/matplotlib/artist.py:1856\u001b[0m, in \u001b[0;36mkwdoc\u001b[0;34m(artist)\u001b[0m\n\u001b[1;32m   1838\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1839\u001b[0m \u001b[38;5;124;03mInspect an `~matplotlib.artist.Artist` class (using `.ArtistInspector`) and\u001b[39;00m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;124;03mreturn information about its settable properties and their current values.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;124;03m    use in Sphinx) if it is True.\u001b[39;00m\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1853\u001b[0m ai \u001b[38;5;241m=\u001b[39m ArtistInspector(artist)\n\u001b[1;32m   1854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(ai\u001b[38;5;241m.\u001b[39mpprint_setters_rest(leadingspace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m   1855\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocstring.hardcopy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m-> 1856\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProperties:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpprint_setters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleadingspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/machine-learning-exam-dnZALQ3X-py3.10/lib/python3.10/site-packages/matplotlib/artist.py:1617\u001b[0m, in \u001b[0;36mArtistInspector.pprint_setters\u001b[0;34m(self, prop, leadingspace)\u001b[0m\n\u001b[1;32m   1615\u001b[0m lines \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_setters()):\n\u001b[0;32m-> 1617\u001b[0m     accepts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_valid_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1618\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maliased_name(prop)\n\u001b[1;32m   1619\u001b[0m     lines\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpad\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccepts\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/machine-learning-exam-dnZALQ3X-py3.10/lib/python3.10/site-packages/matplotlib/artist.py:1500\u001b[0m, in \u001b[0;36mArtistInspector.get_valid_values\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   1497\u001b[0m param_name \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__code__\u001b[39m\u001b[38;5;241m.\u001b[39mco_varnames[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;66;03m# We could set the presence * based on whether the parameter is a\u001b[39;00m\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;66;03m# varargs (it can't be a varkwargs) but it's not really worth it.\u001b[39;00m\n\u001b[0;32m-> 1500\u001b[0m match \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mfr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m(?m)^ *\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m*?\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mparam_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m : (.+)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocstring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match:\n\u001b[1;32m   1502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/re.py:200\u001b[0m, in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5t4uvDVRcaW"
   },
   "source": [
    "Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aEV_AiL5WmUG"
   },
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "    \"A\": {\n",
    "        \"test_est\": pd.read_parquet(os.path.join(\"data\", \"A\", \"X_test_estimated.parquet\")),\n",
    "        \"train_est\": pd.read_parquet(os.path.join(\"data\", \"A\", \"X_train_estimated.parquet\")),\n",
    "        \"train_obs\": pd.read_parquet(os.path.join(\"data\", \"A\", \"X_train_observed.parquet\")),\n",
    "        \"train_tar\": pd.read_parquet(os.path.join(\"data\", \"A\", \"train_targets.parquet\")),\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"test_est\": pd.read_parquet(os.path.join(\"data\", \"B\", \"X_test_estimated.parquet\")),\n",
    "        \"train_est\": pd.read_parquet(os.path.join(\"data\", \"B\", \"X_train_estimated.parquet\")),\n",
    "        \"train_obs\": pd.read_parquet(os.path.join(\"data\", \"B\", \"X_train_observed.parquet\")),\n",
    "        \"train_tar\": pd.read_parquet(os.path.join(\"data\", \"B\", \"train_targets.parquet\")),\n",
    "    },\n",
    "    \"C\": {\n",
    "        \"test_est\": pd.read_parquet(os.path.join(\"data\", \"C\", \"X_test_estimated.parquet\")),\n",
    "        \"train_est\": pd.read_parquet(os.path.join(\"data\", \"C\", \"X_train_estimated.parquet\")),\n",
    "        \"train_obs\": pd.read_parquet(os.path.join(\"data\", \"C\", \"X_train_observed.parquet\")),\n",
    "        \"train_tar\": pd.read_parquet(os.path.join(\"data\", \"C\", \"train_targets.parquet\")),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F05qo-o_cmMI"
   },
   "source": [
    "View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "9DqkRaf2Zcbr",
    "outputId": "a6990325-8e08-4659-901d-ca55a021f408"
   },
   "outputs": [],
   "source": [
    "raw_data[\"C\"][\"test_est\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "-EOXjwvUsLCD",
    "outputId": "c2419a7a-7e70-46c5-dc2b-5e21d9c9b623"
   },
   "outputs": [],
   "source": [
    "raw_data[\"C\"][\"train_est\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "8ZsDiqdyNFyM",
    "outputId": "0fd18788-7141-40a2-ebc1-0435eb0507c9"
   },
   "outputs": [],
   "source": [
    "raw_data[\"C\"][\"train_obs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "yeryCavXTMdz",
    "outputId": "f54837e8-b2c0-46a3-dec4-f2e341c057fd"
   },
   "outputs": [],
   "source": [
    "raw_data[\"C\"][\"train_tar\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZBn2U7-cbjK"
   },
   "source": [
    "Preproccess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_J2JkEttN25R"
   },
   "outputs": [],
   "source": [
    "# Create empty list of location train data and location test data\n",
    "location_train_data = []\n",
    "location_test_data = []\n",
    "\n",
    "# Copy raw data dictonary and loop through it\n",
    "raw_data_copy = copy.deepcopy(raw_data)\n",
    "for k in raw_data_copy:\n",
    "\n",
    "    # Add a column with the difference between date_forecast and date_calc in seconds and remove date_calc\n",
    "    raw_data_copy[k][\"train_obs\"][\"forecast_seconds\"] = 0\n",
    "    raw_data_copy[k][\"train_est\"][\"forecast_seconds\"] = (raw_data_copy[k][\"train_est\"][\"date_forecast\"] - raw_data_copy[k][\"train_est\"][\"date_calc\"]).apply(lambda x: x.total_seconds())\n",
    "    del raw_data_copy[k][\"train_est\"][\"date_calc\"]\n",
    "    raw_data_copy[k][\"test_est\"][\"forecast_seconds\"] = (raw_data_copy[k][\"test_est\"][\"date_forecast\"] - raw_data_copy[k][\"test_est\"][\"date_calc\"]).apply(lambda x: x.total_seconds())\n",
    "    del raw_data_copy[k][\"test_est\"][\"date_calc\"]\n",
    "\n",
    "    # Add a column with location\n",
    "    raw_data_copy[k][\"train_obs\"][\"location\"] = k\n",
    "    raw_data_copy[k][\"train_est\"][\"location\"] = k\n",
    "    raw_data_copy[k][\"test_est\"][\"location\"] = k\n",
    "\n",
    "    # Concat and merge train observed, train estimated and train target to one dataframe and push to location_train_data list\n",
    "    location_train_data.append(pd.merge(\n",
    "        pd.concat([\n",
    "            raw_data_copy[k][\"train_obs\"].rename(columns={\"date_forecast\": \"time\"}),\n",
    "            raw_data_copy[k][\"train_est\"].rename(columns={\"date_forecast\": \"time\"}),\n",
    "        ]),\n",
    "        raw_data_copy[k][\"train_tar\"],\n",
    "        on=\"time\"\n",
    "    ))\n",
    "\n",
    "    # Push test estimate to location test data list\n",
    "    location_test_data.append(raw_data_copy[k][\"test_est\"].rename(columns={\"date_forecast\": \"time\"}))\n",
    "\n",
    "# Concat all the location data and sort by time\n",
    "train_data = pd.concat(location_train_data).dropna(subset=[\"pv_measurement\"]).reset_index()\n",
    "test_data = pd.concat(location_test_data).reset_index()\n",
    "\n",
    "# Remove columns only containing a single or non values\n",
    "cols_to_remove = [col for col in train_data.columns if train_data[col].nunique() <= 1]\n",
    "train_data = train_data.drop(cols_to_remove, axis=1)\n",
    "test_data = test_data.drop(cols_to_remove, axis=1)\n",
    "\n",
    "# Replace all ':' with '_'\n",
    "train_data.columns = [col_name.replace(\":\", \"_\") for col_name in train_data.columns]\n",
    "test_data.columns = [col_name.replace(\":\", \"_\") for col_name in test_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "id": "f3ofLa3OcflP",
    "outputId": "9d815a26-c833-4574-b8c8-0ac200207975"
   },
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9BV3HOmc7bP"
   },
   "source": [
    "Analyse train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "bwACqCTCdZ7F",
    "outputId": "2b7e1963-29b4-42df-dbce-c61b5aa6e362"
   },
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rEJl9ajZdHeD",
    "outputId": "20ed5c60-7a8c-4ecc-d3db-80319ee395ea"
   },
   "outputs": [],
   "source": [
    "train_data.hist(figsize=(20,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "e1KPhOeVaFI8",
    "outputId": "f2381b56-f56b-47d1-9e5c-8dee2a0216f5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, column in enumerate(train_data.columns, 1):\n",
    "    print(f\"{i}. {column}\")\n",
    "\n",
    "plt.matshow(train_data.corr(), cmap=\"PRGn\", interpolation=\"none\", vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiPWk97Gqgwj"
   },
   "source": [
    "# Pycaret regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01Zdq2vwcMcC"
   },
   "source": [
    "Import pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 789
    },
    "id": "5DKga8vhPkud",
    "outputId": "4eaa8162-7441-4777-e883-4661834ab8f6"
   },
   "outputs": [],
   "source": [
    "from pycaret.regression import RegressionExperiment\n",
    "exp = RegressionExperiment()\n",
    "n_select = 5 # Select the top n models\n",
    "turbo = False # Filter away slow models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.setup(\n",
    "    train_data, \n",
    "    target = 'pv_measurement', \n",
    "    create_date_columns = ['hour', 'day', 'month', 'year'],\n",
    "    #imputation_type = 'iterative',\n",
    "    #numeric_iterative_imputer = 'et',\n",
    "    #normalize = True,\n",
    "    #transformation = True,\n",
    "    #pca = True,\n",
    "    #pca_components = 'mle',\n",
    "    #polynomial_features = True,\n",
    "    #remove_multicollinearity = True,\n",
    "    feature_selection = True, \n",
    "    #n_features_to_select = 0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_top_models = exp.compare_models(sort='MAE', turbo=turbo, n_select=n_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model_best = basic_top_models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(basic_model_best, plot = 'residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(basic_model_best, plot = 'error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_model(basic_model_best, plot = 'feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine top models with stacked and blended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic_model_blended = exp.blend_models(basic_top_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic_model_stacked = exp.stack_models(basic_top_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model_best = exp.finalize_model(basic_top_models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic_model_blended = exp.finalize_model(basic_model_blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic_model_stacked = exp.finalize_model(basic_model_stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.save_model(basic_model_best, 'basic_model_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp.save_model(basic_model_blended, 'basic_model_blended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp.save_model(basic_model_stacked, 'basic_model_stacked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model_best = exp.load_model('basic_model_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic_model_blended = exp.load_model('basic_model_blended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic_model_stacked = exp.load_model('basic_model_stacked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predicted_data = predict_model(basic_model_best, data = test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacked_predicted_data = predict_model(basic_model_stacked, data = test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blended_predicted_data = predict_model(basic_model_blended, data = test_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
